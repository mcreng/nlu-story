{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlu_story_cls_baseline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "igrpjJsZfW8-",
        "colab_type": "code",
        "outputId": "134bd993-782e-4eee-8ba6-6d4582a7ebd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  COLAB = True\n",
        "except:\n",
        "  COLAB = False"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkwWzK7kHC2",
        "colab_type": "code",
        "outputId": "ffe266d8-4343-4160-e7bc-a5a67afbb65f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras.preprocessing.text as kpt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Embedding, Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import load_model, Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5JMG-vlOtc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1027fb09-054a-4d78-f985-c9a3d3339b1e"
      },
      "source": [
        "TRAIN_URL = '/content/drive/My Drive/Coding/nlu-story/train_stories.csv' if COLAB else '../train_stories.csv'\n",
        "\n",
        "df_train = pd.read_csv(TRAIN_URL).iloc[:, 2:]\n",
        "df_train['sentence6'] = df_train.iloc[:, 4].shift(periods=-1, fill_value=df_train.iloc[0, 4]) # sentence 5 shifted 1 row\n",
        "\n",
        "n_samples = len(df_train)\n",
        "\n",
        "df_train = df_train.assign(y=pd.Series(np.random.randint(2, size=n_samples)).values)\n",
        "swap_idx = (df_train.y == 1)\n",
        "df_train.loc[swap_idx,['sentence5','sentence6']] = df_train.loc[swap_idx,['sentence6','sentence5']].values # swap sentences 5 & 6 uniformly\n",
        "\n",
        "df_train['X'] = df_train[['sentence1', 'sentence2', 'sentence3', 'sentence4', 'sentence5', 'sentence6']].apply(lambda x: ' '.join(x), axis=1)\n",
        "df_train = df_train[['X', 'y']]\n",
        "\n",
        "print(df_train.shape)\n",
        "print(df_train.iloc[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(88161, 2)\n",
            "X    Kelly found her grandmother's pizza recipe in ...\n",
            "y                                                    1\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWEWJ-EmjoSc",
        "colab_type": "code",
        "outputId": "b0901bce-4277-4199-9d4c-4a666c9af848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "VOCAB_SIZE = 20000\n",
        "\n",
        "tokenizer = kpt.Tokenizer(oov_token='<UNK>', num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(df_train['X'])\n",
        "tokenizer.word_index = {w:i for w,i in tokenizer.word_index.items() if i < VOCAB_SIZE}\n",
        "\n",
        "vocab_dict = tokenizer.word_index\n",
        "print(len(vocab_dict)+1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqr7H4JGdtbj",
        "colab_type": "code",
        "outputId": "2272cfc3-755c-42be-816a-2f4265c292dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = tokenizer.texts_to_sequences(df_train['X'])\n",
        "seq_len = max(len(s) for s in X_train)\n",
        "X_train = pad_sequences(X_train, maxlen=seq_len, padding='post')\n",
        "\n",
        "y_train = df_train.y\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(88161, 87) (88161,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0e0JtNTpnV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "660359aa-46d7-4a88-9663-f586f1e99cfe"
      },
      "source": [
        "EMB_SIZE = 100\n",
        "GLOVE_URL = '/content/drive/My Drive/Coding/nlu-story/glove.6B.100d.txt' if COLAB else '../glove.6B.100d.txt'\n",
        "\n",
        "embeddings = {}\n",
        "with open(GLOVE_URL, 'r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        w = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings[w] = coefs\n",
        "\n",
        "print(len(embeddings))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73AMGuJF7M5w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1acfd32b-7668-4366-d87a-0d9c81e6685e"
      },
      "source": [
        "embedding_matrix = np.random.uniform(-1, 1, size=(VOCAB_SIZE, EMB_SIZE))\n",
        "num_loaded = 0\n",
        "for w, i in vocab_dict.items():\n",
        "    if w in embeddings and i < VOCAB_SIZE:\n",
        "        embedding_matrix[i] = embeddings[w]\n",
        "        num_loaded += 1\n",
        "\n",
        "print(embedding_matrix.shape, num_loaded)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 100) 18894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw3lX8ay7POD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "aa2f414c-d71a-4c8c-891c-c968d1dd2bf7"
      },
      "source": [
        "MODEL_URL = '/content/drive/My Drive/Coding/nlu-story/model.h5' if COLAB else './model.h5'\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(VOCAB_SIZE, EMB_SIZE, weights=[embedding_matrix], input_length=seq_len, trainable=True))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "try:\n",
        "    model = load_model(MODEL_URL)\n",
        "    print('Loaded previous model.')\n",
        "except:\n",
        "    model = create_model()\n",
        "    print('Created new model.')\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Created new model.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 87, 100)           2000000   \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8700)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               4454912   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 6,455,425\n",
            "Trainable params: 6,455,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9ax7Sh47R3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "d3039ec3-1c84-4f7d-d552-0d0e9a0a396b"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "ckpt = ModelCheckpoint(filepath=MODEL_URL, verbose=0, save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[ckpt]\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 70528 samples, validate on 17633 samples\n",
            "Epoch 1/10\n",
            "70528/70528 [==============================] - 17s 245us/step - loss: 1.9507 - acc: 0.4983 - val_loss: 0.6928 - val_acc: 0.5115\n",
            "Epoch 2/10\n",
            "70528/70528 [==============================] - 17s 236us/step - loss: 0.6884 - acc: 0.5418 - val_loss: 0.6953 - val_acc: 0.5095\n",
            "Epoch 3/10\n",
            "70528/70528 [==============================] - 17s 235us/step - loss: 0.6489 - acc: 0.6205 - val_loss: 0.7433 - val_acc: 0.5098\n",
            "Epoch 4/10\n",
            "70528/70528 [==============================] - 17s 237us/step - loss: 0.4788 - acc: 0.7708 - val_loss: 0.9129 - val_acc: 0.5115\n",
            "Epoch 5/10\n",
            "70528/70528 [==============================] - 17s 237us/step - loss: 0.2627 - acc: 0.8918 - val_loss: 1.3701 - val_acc: 0.5115\n",
            "Epoch 6/10\n",
            "70528/70528 [==============================] - 16s 233us/step - loss: 0.1082 - acc: 0.9608 - val_loss: 2.0060 - val_acc: 0.5096\n",
            "Epoch 7/10\n",
            "70528/70528 [==============================] - 16s 233us/step - loss: 0.0361 - acc: 0.9881 - val_loss: 3.0587 - val_acc: 0.5077\n",
            "Epoch 8/10\n",
            "70528/70528 [==============================] - 16s 233us/step - loss: 0.0200 - acc: 0.9930 - val_loss: 3.6321 - val_acc: 0.5077\n",
            "Epoch 9/10\n",
            "70528/70528 [==============================] - 17s 238us/step - loss: 0.0149 - acc: 0.9946 - val_loss: 3.8106 - val_acc: 0.5092\n",
            "Epoch 10/10\n",
            "70528/70528 [==============================] - 17s 235us/step - loss: 0.0148 - acc: 0.9949 - val_loss: 4.2088 - val_acc: 0.5076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f01414549e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfM-eBaA79TV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1db59bce-e9dc-4d09-afa9-a42dce21db24"
      },
      "source": [
        "EVAL_URL = '/content/drive/My Drive/Coding/nlu-story/eval_stories.csv' if COLAB else '../eval_stories.csv'\n",
        "\n",
        "df_eval = pd.read_csv(EVAL_URL).iloc[:, 1:8]\n",
        "df_eval['X'] = df_eval[['InputSentence1', 'InputSentence2', 'InputSentence3', 'InputSentence4', 'RandomFifthSentenceQuiz1', 'RandomFifthSentenceQuiz2']].apply(lambda x: ' '.join(x), axis=1)\n",
        "df_eval['y'] = df_eval['AnswerRightEnding'].apply(lambda x: x-1)\n",
        "df_eval = df_eval[['X', 'y']]\n",
        "\n",
        "print(df_eval.shape)\n",
        "print(df_eval.iloc[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1871, 2)\n",
            "X    Rick grew up in a troubled household. He never...\n",
            "y                                                    0\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9fzNvg7NKIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "632ebfc8-c1fd-4695-d264-2c9263c1ee7a"
      },
      "source": [
        "correct = 0\n",
        "total = len(df_eval)\n",
        "for i, row in df_eval.iterrows():\n",
        "    X_eval = tokenizer.texts_to_sequences([row['X']])\n",
        "    X_eval = pad_sequences(X_eval, maxlen=seq_len, padding='post')\n",
        "    y_pred = model.predict(X_eval)\n",
        "    if y_pred >= 0.5 and row['y'] == 1 or y_pred < 0.5 and row['y'] == 0:\n",
        "      correct += 1\n",
        "\n",
        "acc = correct / total\n",
        "\n",
        "print(correct, total, acc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "949 1871 0.5072153928380545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPCqLhmrPfVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}